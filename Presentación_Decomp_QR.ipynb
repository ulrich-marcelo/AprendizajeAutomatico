{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaebc90c",
   "metadata": {},
   "source": [
    "Para la presentación, qué necesito?\n",
    "\n",
    "0. Repaso conceptual:\n",
    "    a. Matrices como Transformaciones lineales\n",
    "    b. Minimos cuadrados (notación matricial)\n",
    "1. Explicar el tema:\n",
    "    a. En qué consiste? Lineas generales\n",
    "    b. Por qué nos sirve\n",
    "    c. Cómo se hace?\n",
    "2. Autores del libro? No es paper, quizás es un extra si veo que no llego con el tiempo\n",
    "3. Ejemplos en codigo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107cca6",
   "metadata": {},
   "source": [
    "# Repaso\n",
    "\n",
    "Antes de arrancar, vamos con un repaso (rápido) de los temas necesarios para entender la descomposición QR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe744a",
   "metadata": {},
   "source": [
    "## Regresión Lineal\n",
    "\n",
    "Tenemos $X_{original}^T = (X_1, X_2,..., X_p) $ y el vector $Y = (y_1, y_2, ..., y_n)$. \n",
    "\n",
    "La regresión lineal asume $$ \\hat{Y}  = \\beta_0 + \\sum_{j=1}^{p} X_j \\beta_j$$\n",
    "$$ \\hat{Y} = X^T \\beta $$ $$\\text{ con }  X^T = [ 1 | X_{original}^T ]$$\n",
    "\n",
    "Por lo tanto,  buscamos estimar $\\beta$ que minimice una función de costos/error. En general usamos Minimos Cuadrados, que busca minimizar $$RSS(\\beta) = \\sum_{i=1}^{N} (y_i - \\hat{y}_i(\\beta))^2$$\n",
    "\n",
    "obteniendo así el Estimador de Cuadrados Minimos:\n",
    "$$\\hat{\\beta} = (\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T \\textbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ade55",
   "metadata": {},
   "source": [
    "Todo joya hasta que $X^TX$ no es invertible.\n",
    "\n",
    "Esto pasa cuando hay al menos un vector columna $X_i$ que es linealmente dependiente de otro(s).\n",
    "\n",
    "El problema es que esto es muy frecuente en _la naturaleza_ (todo conjunto de datos no generado artificialmente).\n",
    "\n",
    "Animaciones de porqué es el problema (ver 3b1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68084293",
   "metadata": {},
   "source": [
    "Y ahora quien podrá ayudarnos??\n",
    "\n",
    "[insertar meme]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbed804",
   "metadata": {},
   "source": [
    "Ya vimos SVD, hoy les traigo otro metodo de descomposición de matrices... Descomposición QR.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ff300",
   "metadata": {},
   "source": [
    "# Descomposición QR\n",
    "\n",
    "Así cómo en Singular Value Deocmposition $X = U D V^T$, este metodo propone descomponer X en otras matrices. En particular\n",
    "$$ X = QR $$\n",
    "Obvio\n",
    "\n",
    "La matriz Q es de NxP+1 y ortogonal (lease, vectores columna linealmente independientes).\n",
    "La matriz R es de P+1xP+1 y triangular superior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f8337",
   "metadata": {},
   "source": [
    "Ok, y???\n",
    "\n",
    "La gracia es que al reemplazar en la formula del Estimador de Cuadrados Minimos, genera lo siguiente:\n",
    "\n",
    "$$\\hat{\\beta} = (\\textbf{X}^T \\textbf{X})^{-1} \\textbf{X}^T \\textbf{y}$$\n",
    "$$\\hat{\\beta} = (\\textbf{(QR)}^T \\textbf{QR})^{-1} \\textbf{(QR)}^T \\textbf{y}$$\n",
    "$$\\hat{\\beta} = (\\textbf{R}^T \\textbf{Q}^T \\textbf{QR})^{-1} \\textbf{R}^T \\textbf{Q}^T \\textbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2058fc",
   "metadata": {},
   "source": [
    "$$\\hat{\\beta} = (\\textbf{R}^T \\textbf{Q}^T \\textbf{QR})^{-1} \\textbf{R}^T \\textbf{Q}^T \\textbf{y}$$\n",
    "\n",
    "Como $Q$ es ortogonal, vale que $Q^T Q = Q Q^T = I$, entonces:\n",
    "\n",
    "$$\\hat{\\beta} = (\\textbf{R}^T \\textbf{I} \\textbf{R})^{-1} \\textbf{R}^T \\textbf{Q}^T \\textbf{y}$$\n",
    "\n",
    "$$\\hat{\\beta} = (\\textbf{R}^T \\textbf{R})^{-1} \\textbf{R}^T \\textbf{Q}^T \\textbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31acffa6",
   "metadata": {},
   "source": [
    "## Vectores y Matrices\n",
    "\n",
    "Lo necesario es lo siguiente:\n",
    "\n",
    "1. Vectores:\n",
    "    a. Producto Interno entre vectores:\n",
    "        1. definicion\n",
    "        2. propiedad aditiva\n",
    "        3. ortogonalidad\n",
    "2. Matrices:\n",
    "    a. Matriz como transformación lineal \n",
    "    b. Descomposición\n",
    "\n",
    "Matriz Inversa:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a0b1c5",
   "metadata": {},
   "source": [
    "# Descomposición QR\n",
    "\n",
    "1. Qué es?\n",
    "    a. Forma de descomponer matriz X en dos componentes\n",
    "        1. Q: matriz ortogonal\n",
    "        2. R: matriz triangular superior\n",
    "2. Por qué me interesa?\n",
    "    a. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
